{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "import os\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml\") \n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "def detect_mask(np_image,threshold=0.30):\n",
    "    predictions = predictor(np_image)\n",
    "    visualizer = Visualizer(np_image)\n",
    "\n",
    "    instances = predictions[\"instances\"].to(torch.device(\"cpu\"))\n",
    "    instances = instances[instances.pred_classes==2]\n",
    "    if len(instances) > 0:\n",
    "        filtered_instances = instances[instances.scores > threshold]\n",
    "\n",
    "        if len(filtered_instances) == 0:\n",
    "            filtered_instances = instances[instances.scores == instances.scores.max()]\n",
    "    else:\n",
    "        filtered_instances = instances\n",
    "\n",
    "    vis_output = visualizer.draw_instance_predictions(predictions=filtered_instances)\n",
    "    return vis_output.get_image(),filtered_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"../images/Flood/\"\n",
    "label_folder = \"../images/labels/\"\n",
    "mask_result_folder = \"../result_mask/\"\n",
    "file_names = os.listdir(image_folder)\n",
    "# image_name = \"Flood_27.jpg\"  # \"Flood_183.jpg\" flip\n",
    "for image_name in file_names:\n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    label_name = base_name+\".json\"\n",
    "\n",
    "    pil_image = Image.open(image_folder+image_name)\n",
    "    im_width, im_height = pil_image.size\n",
    "    np_image = np.array(pil_image)\n",
    "\n",
    "    result,instances = detect_mask(np_image,0.30)\n",
    "\n",
    "    Image.fromarray(result).save(mask_result_folder+image_name)\n",
    "\n",
    "    data = {\"cars\":[]}\n",
    "    \n",
    "    for i in range(0,len(instances)):\n",
    "        box = instances.pred_boxes[i].tensor.numpy()[0]\n",
    "        mask = np.zeros((im_height,im_width))\n",
    "        mask[instances.pred_masks[i].numpy()] = 1\n",
    "        data[\"cars\"].append({\"box\":box.tolist(),\"mask\":mask.tolist()})\n",
    "\n",
    "    with open(mask_result_folder+base_name+\".json\",\"w\") as file:\n",
    "        file.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"../images/Flood/\"\n",
    "image_name = \"Flood_1457.jpg\"\n",
    "\n",
    "pil_image = Image.open(image_folder+image_name)\n",
    "im_width, im_height = pil_image.size\n",
    "np_image = np.array(pil_image)\n",
    "\n",
    "predictions = predictor(np_image)\n",
    "visualizer = Visualizer(np_image)\n",
    "\n",
    "instances = predictions[\"instances\"].to(torch.device(\"cpu\"))\n",
    "instances = instances[instances.pred_classes==2]\n",
    "if len(instances) > 0:\n",
    "    filtered_instances = instances[instances.scores > 0.91]\n",
    "    # filtered_instances = filtered_instances[filtered_instances.scores < 0.20]\n",
    "\n",
    "    if len(filtered_instances) == 0:\n",
    "        filtered_instances = instances[instances.scores == instances.scores.max()]\n",
    "else:\n",
    "    filtered_instances = instances\n",
    "\n",
    "vis_output = visualizer.draw_instance_predictions(predictions=filtered_instances)\n",
    "\n",
    "\n",
    "base_name = os.path.splitext(image_name)[0]\n",
    "data = {\"cars\":[]}\n",
    "for i in range(0,len(filtered_instances)):\n",
    "    box = filtered_instances.pred_boxes[i].tensor.numpy()[0]\n",
    "    mask = np.zeros((im_height,im_width))\n",
    "    mask[filtered_instances.pred_masks[i].numpy()] = 1\n",
    "    data[\"cars\"].append({\"box\":box.tolist(),\"mask\":mask.tolist()})\n",
    "\n",
    "with open(mask_result_folder+base_name+\".json\",\"w\") as file:\n",
    "    file.write(json.dumps(data))\n",
    "\n",
    "Image.fromarray(vis_output.get_image()).save(mask_result_folder+image_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hiwi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
