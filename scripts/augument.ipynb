{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"D:\\\\Program\\\\Apollo\\\\instance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"apollo_sample\", {}, \"./sample/apollo_sample.json\", dataset_folder + \"/train/images\")\n",
    "\n",
    "with open(\"./configs/apollo_meta.json\",'r') as load_f:\n",
    "    apollo_metadata = json.load(load_f)\n",
    "\n",
    "MetadataCatalog.get(\"apollo_sample\").keypoint_names = apollo_metadata['APOLLO_CAR_KEYPOINT_NAMES']\n",
    "MetadataCatalog.get(\"apollo_sample\").keypoint_flip_map = apollo_metadata['APOLLO_CAR_KEYPOINT_FLIP_MAP']\n",
    "MetadataCatalog.get(\"apollo_sample\").keypoint_connection_rules = apollo_metadata['APOLLO_CAR_KEYPOINT_CONNECTION_RULES']\n",
    "MetadataCatalog.get(\"apollo_sample\").thing_classes = ['car']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self defined Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import transforms as T\n",
    "from fvcore.transforms.transform import CropTransform\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RandomZoom(T.Augmentation):\n",
    "    def get_transform(self, image, boxes):\n",
    "        h, w = image.shape[:2]\n",
    "        croph = round(h*0.3)\n",
    "        cropw = round(w*0.5)\n",
    "        assert h >= croph and w >= cropw, \"Shape computation in {} has bugs.\".format(self)\n",
    "        h0 = np.random.randint(h - croph + 1)\n",
    "        w0 = np.random.randint(w - cropw + 1)\n",
    "\n",
    "        return CropTransform(w0, h0, cropw, croph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import DatasetMapper   # the default mapper\n",
    "from detectron2.data import detection_utils as utils\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"./configs/Apollo-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\") \n",
    "cfg.DATASETS.TRAIN = 'apollo_sample'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "data_loader = build_detection_train_loader(cfg,\n",
    "   mapper=None)\n",
    "\n",
    "iterator = iter(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Program\\WaterLevelEstimator\\augument.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Program/WaterLevelEstimator/augument.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m numpy_img \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mconvert_image_to_rgb(numpy_img, cfg\u001b[39m.\u001b[39mINPUT\u001b[39m.\u001b[39mFORMAT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Program/WaterLevelEstimator/augument.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mAugInput(numpy_img, boxes\u001b[39m=\u001b[39msample[\u001b[39m\"\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mgt_boxes)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Program/WaterLevelEstimator/augument.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m transforms \u001b[39m=\u001b[39m augs(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Program/WaterLevelEstimator/augument.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(numpy_img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Program/WaterLevelEstimator/augument.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\JuJuBear\\.conda\\envs\\Hiwi\\lib\\site-packages\\detectron2-0.6-py3.8-win-amd64.egg\\detectron2\\data\\transforms\\augmentation.py:173\u001b[0m, in \u001b[0;36mAugmentation.__call__\u001b[1;34m(self, aug_input)\u001b[0m\n\u001b[0;32m    168\u001b[0m tfm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_transform(\u001b[39m*\u001b[39margs)\n\u001b[0;32m    169\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tfm, (Transform, TransformList)), (\n\u001b[0;32m    170\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.get_transform must return an instance of Transform! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tfm)\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m )\n\u001b[1;32m--> 173\u001b[0m aug_input\u001b[39m.\u001b[39;49mtransform(tfm)\n\u001b[0;32m    174\u001b[0m \u001b[39mreturn\u001b[39;00m tfm\n",
      "File \u001b[1;32mc:\\Users\\JuJuBear\\.conda\\envs\\Hiwi\\lib\\site-packages\\detectron2-0.6-py3.8-win-amd64.egg\\detectron2\\data\\transforms\\augmentation.py:340\u001b[0m, in \u001b[0;36mAugInput.transform\u001b[1;34m(self, tfm)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage \u001b[39m=\u001b[39m tfm\u001b[39m.\u001b[39mapply_image(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage)\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboxes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboxes \u001b[39m=\u001b[39m tfm\u001b[39m.\u001b[39;49mapply_box(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboxes)\n\u001b[0;32m    341\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msem_seg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msem_seg \u001b[39m=\u001b[39m tfm\u001b[39m.\u001b[39mapply_segmentation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msem_seg)\n",
      "File \u001b[1;32mc:\\Users\\JuJuBear\\.conda\\envs\\Hiwi\\lib\\site-packages\\fvcore-0.1.5.post20221221-py3.8.egg\\fvcore\\transforms\\transform.py:128\u001b[0m, in \u001b[0;36mTransform.apply_box\u001b[1;34m(self, box)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m# Indexes of converting (x0, y0, x1, y1) box into 4 coordinates of\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m# ([x0, y0], [x1, y0], [x0, y1], [x1, y1]).\u001b[39;00m\n\u001b[0;32m    127\u001b[0m idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m), (\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m), (\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m), (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)])\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m--> 128\u001b[0m coords \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(box)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)[:, idxs]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    129\u001b[0m coords \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_coords(coords)\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m    130\u001b[0m minxy \u001b[39m=\u001b[39m coords\u001b[39m.\u001b[39mmin(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\JuJuBear\\.conda\\envs\\Hiwi\\lib\\site-packages\\numpy\\core\\_asarray.py:83\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masarray\u001b[39m(a, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\"\"Convert the input to an array.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "batch = next(iterator)\n",
    "\n",
    "sample = batch[0]\n",
    "\n",
    "augs = RandomZoom()\n",
    "\n",
    "\n",
    "\n",
    "# get the image from sample and convert from tensor to numpy\n",
    "numpy_img = sample[\"image\"].permute(1, 2, 0).cpu().detach().numpy()\n",
    "numpy_img = utils.convert_image_to_rgb(numpy_img, cfg.INPUT.FORMAT)\n",
    "\n",
    "input = T.AugInput(numpy_img, boxes=sample[\"instances\"].gt_boxes)\n",
    "transforms = augs(input)\n",
    "\n",
    "plt.imshow(numpy_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hiwi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
